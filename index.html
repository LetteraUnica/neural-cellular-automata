<!doctype html>
<meta charset="utf-8">
<script src="website/template.js"></script>
<script src="https://d3js.org/d3.v4.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-BMS9095G9B"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-BMS9095G9B');
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css" integrity="sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js" integrity="sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          // customised options
          // • auto-render specific keys, e.g.:
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          // • rendering keys, e.g.:
          throwOnError : false
        });
    });
</script>

<script type="text/front-matter">
  title: "Stopping Aging in Neural Cellular Automata"
  description: "Description of the post"
  authors:
  - Lorenzo Cavuoti: https://github.com/LetteraUnica
  - Francesco Sacco: http://github.com/Francesco215
  affiliations:
  - University of Trieste: http://units.it
  - University of Pisa: http://unipi.it
</script>

<dt-article>
  <h1>Stopping Aging in Neural Cellular Automata</h1>
  <h2>
    In this paper we are going to discuss the condition necessary to make a mortal
    neural cellular automata, immortal
  </h2>
  <dt-byline></dt-byline>
  <figure class="l-middle side">
    <video loop="" autoplay="" playsinline="" muted="" width="100%" height="100%">
      <source src="pytorch_ca/Presentation_videos/stable.mp4" type="video/mp4" id="stable">
      Your browser does not support the video tag.
    </video>
    <figcaption>
      Figure 1: Example of Regenerating CA <dt-cite key="mordvintsev2020growing"></dt-cite>
    </figcaption>
  </figure>
  <p>
    Most living organisms age and eventually die because of it, but a few don’t, and some of
    them are incredibly hard to kill, even if you cut their head off, it just regrows
    <dt-cite key="handberg2008stem"></dt-cite>.
    Neural Cellular Automata are a very good representation of living organisms: scientists managed
    to create cellural automatas that are able to represent any image, some of them after a while
    decay (figure <a href="#unstable">2</a>), others manage to maintain the final state, and some
    of them are even able to regenerate damage. (figure <a href="#stable">1</a>)
    <dt-cite key="mordvintsev2020growing"></dt-cite>
  </p>
  <figure class="l-middle outset">
    <video loop="" autoplay="" playsinline="" muted="" width="100%" height="100%">
      <source src="pytorch_ca/Presentation_videos/unstable.mp4" type="video/mp4" id="unstable">
      Your browser does not support the video tag.
    </video>
    <figcaption>
      Figure 2: Example of Growing CA, as you can see, they eventually degrade <dt-cite key="mordvintsev2020growing"></dt-cite>
    </figcaption>
  </figure>










  
  <dt-byline></dt-byline>
  <h2><a class="marker" href="#intro" id="intro"></a>Introduction</h2>
  <p>
    Throughout this paper we are going to use different terms to refer to different types of cellular automatas:
    <ul>
      <li>With “Growing” with capital letter we indicate a neural cellular automata that grows into a final state and then decays, this represents growing and aging biological organisms</li>
      <li>With “Persistent” we indicate a cellular automaton that grows into a final state and then keeps it for an infinite amount of time, some biological organisms like lobsters have this property.</li>
      <li>Finally with “Regenerating” we refer to persistent organisms that are even able to regenerate damage and have a infinite lifespan, biological examples of these are the  planarians.</li>
    </ul>
  </p>
  <p>
    Biological organisms often times blur the line between this categories, for example most aging organisms like ourselves
    are able to heal wounds and some like salamanders are even able to regenerate missing limbs,
    for practical reasons, however, we are going to stick with these 3 categories
  </p>
  <p>Sometimes we will abbreviate Cellular Automata with CA to make the descriptions less verbose</p>
  <h2><a class="marker" href="#section-1" id="section-1">1</a> Switching the Rule</h2>
  <p>
    First of all we wanted to know if it is possible to take a cellular automata
    in the growing mode and after a arbitrary number $n$ of steps 
    <dt-fn> By arbitrary we mean any number of steps before the cellular automata decays</dt-fn>
    we switch the update rule in order to make it Regenerating. We can write it mathematically like this 
    $$
      \begin{cases}
        x_{new}=f_1(x_{old})\quad \textrm{ if }\quad n_{iter} \le n\\
        x_{new}=f_2(x_{old})\quad \textrm{ if }\quad n_{iter} > n
      \end{cases}
    $$
  </p>
  <p>
    Where $f_1$ is a growing rule and $f_2$ is a rule that we trained to make the organism Regenerating
    <dt-fn>$n$ in this case should be considered a parameter, that is, if we change $n$ we don't need to change $f_2$, so the switch can happen at any iteration</dt-fn>
  </p>

  <p>
    To make a parallel with a biological system, this is equivalent to asking:
    Is it possible to make an organism immortal if we have the ability to change its DNA in every single cell
    at once?
    <dt-fn>
      This is not entirely a correct statement since there are more ways to change the behaviour of
      a biological system, for example you can do so by changing the electric potential <dt-cite key="TransmembraneVoltagePotential"></dt-cite>.
      There is also the possibility that some changes to the update rule are impossible to encode in the DNA by itself,
      so the best way to view the switch is by considering it as a change in the way the cells operate.
    </dt-fn> 
  </p>
  <p>
    Since we had already trained a Regenerating CA we tried to substitute it directly into $f_2$, the result
    however was a complete failure as can be seen from the video below where the switch happens at $n=30$
  </p>
  <figure class="l-middle side">
    <video loop="" autoplay="" playsinline="" muted="" width="100%" height="100%">
      <source src="pytorch_ca/Presentation_videos/rswitch40.mp4" type="video/mp4" id="boom">
      Your browser does not support the video tag.
    </video>
    <figcaption>
      This is what happens when we evolve the CA with a $f_1$ that is Growing and then
      switch to a $f_2$ that is Regenerating after 40 steps
    </figcaption>
  </figure>
  <p>
    This outcome at first sight might be surprising, because as can be seen in the first video the visible
    RGBA channels of the cell evolve in a similar fashion in the growing and regenerating CA. The hidden
    channels however, which are the ones used by the cells to transfer information between them, are
    in general completely different, which makes the two CAs incompatible.
  </p>
  <p>
    A simple example is: suppose that $f_1$ uses hidden channel $1$ to tell if the cell has a dead neighbor,
    while $f_2$ uses hidden channel $2$ to pass the same information. If we switch the update rule midway, $f_2$
    can’t understand what $f_1$ has encoded and will likely lead to a disruption of the organism.
  </p>
  <p>
    We can show this behaviour empirically by visualizing the hidden states of the two CAs after they reached
    the target state, below we plotted the 6th hidden state after 300 steps of two regenerating CAs trained independently.
  </p>

  <figure class='l-body'>
    <img src="pytorch_ca/Presentation_images/regenerating2_channel_6.png" style='height: 50%; width: 49%; object-fit: contain' id="80%video">
    <img src="pytorch_ca/Presentation_images/regenerating_channel_6.png" style='height: 50%; width: 49%; object-fit: contain' id="80%mask">
      <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
        Figure 2: The 6th hidden state after 300 interations of two Regenerating CAs trained independently,
        we can see that the CA on the left uses this hidden state to encode something similar to a $x$ coordinate,
        while the CA on the right uses the hidden state to represent a sort of distance from the center
      </figcaption>
    </figure>

  <p>
    This means that to make the model work as intended we must train $f_2$ with the goal of making the organism
    regenerating, we will call the trained $f_2$ rule Switch.
    The only difference between training a Regenerating CA and Switch is the starting pool: instead
    of starting with a single dot on the canvas, the pool is initialized by having each element be the output
    of $n$ steps of the Growing CA $f_1$. That way Switch learns to start from a state of a Growing CA and reach the
    state of a Regenerating one.
    <dt-fn>
      The training seemed to be highly dependent from the starting parameters, in particular if we
      started from a Regenerating CA the net seemed to converge faster, instead
      if we started from a random initialization often times it didn't converge
    </dt-fn>
  </p>
  <figure class="l-middle outset">
    <img src="pytorch_ca/Presentation_images/collage switch.png" alt="training pool" width="100%" height="100%">
    <figcaption>
      Figure 3: Sample of 15 images from the training pool used to train the Switch CA
    </figcaption>
  </figure>
  <p>
    So, does it work if we train Switch with this method?
    The answer is yes. Video <a href="#image-1">1</a> shows you what happens.
  </p>
  <figure class="l-middle side">
    <img src="pytorch_ca/switch_visuals/switch60.gif" style='height: 100%; width: 100%; object-fit: contain' id="switch">
    <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
      Video 1: Here the rule switches at the 60th step, you can clearly see when the switch happens
    </figcaption>
  </figure>
  <h3>Some considerations</h3>
  <p>
    As already explained above, different CA rules will use different encodings to store the informations of
    the organisms, so here are some other things that you can’t do:
    <ul>
      <li>
        You can’t use a Switch CA for a Growing one which has not been trained for
        <dt-fn>The Switch rule is tailor-made to be able to understand the specific encoding of the Growing rule</dt-fn>
      </li>
      <li>You cannot just swap the Growing rule with another Regenerating (or Persist) rule
        <dt-fn>For the same reason of the one above and because the regenerating (and the persist) are trained with different starting points </dt-fn>
      </li>
      <li>You cannot salvage a Growing rule that has decayed
        <dt-fn>We are not trying to resuscitate the dead, and so we didn’t train for it</dt-fn>
      </li>
    </ul>
  </p>











  <dt-byline></dt-byline>
  <h2><a class="marker" href="#section-2" id="section-2">2</a> Virus with fixed mask</h2>
  <p>
    “The Switch” has some relevant problems that need to be addressed.
  </p>
  <p>
    First of all during the transition from one rule to the next the system undergoes a major restructuring.
    <dt-fn>
      You can see it from video 1: when the switch happens the organism becomes amorphus.
    </dt-fn>
    If this was a living organism that needs it’s organs to function 24h a day it will probably die before
    the transition is completed.
  </p>
  <p>
    The second problem is that we need to change every single cell of the organism in order to make it immortal,
    in practice, however, we aren’t going to have the precision necessary
    to be able to influence every single cell of a organism without missing even one, and,
    as you can see from the video below, if some of the cells (marked in blue) don’t transition from $f_1$
    to $f_2$ the organism decays rather quickly.
  </p>
  <figure class='l-middle'>
    <img src="pytorch_ca/Presentation_images/mask_switch.png" style='height: 45%; width: 45%; object-fit: contain' id="mask_swich">
    <img src="pytorch_ca/Presentation_videos/switch40-99.7_.gif" style='height: 45%; width: 45%; object-fit: contain' id="wrong_switch">
    <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
      Video 2: On the left we plotted the cell mask, where the yellow cells evolve according to $f_2$ and the blue ones to $f_1$,
      while on the right you can see the evolution video.
      We can see that leaving only a couple of cells with the old update rule can be catastrophic for the organism
    </figcaption>
  </figure>
  <p>
    Randazzo et al. published a paper<dt-cite key="randazzo2021adversarial"></dt-cite>
    in which they change the global properties of a CA by adding some cells that follow a different rule, so the next thing
    that we tried to do was to train a $f_2$ that would be able to make a Growing CA into a Persist even
    if not all the cells, follow $f_2$ after the switch has happened.
    The training proceeds as before, however we switch the update rule of only a percentage of the cells
  </p>
  <p>
    In video 3 we show what happens with a CA rule trained to switch 70% of the cells. With this technique
    we were able to make the switch more flexible and at the same time we managed to avoid the restructuring phase without training for it.
    <dt-fn>
      This is because by having some of the old cells still around, the new rule has to learn to
      collaborate and influence the old cells to be able to reach a stationary state.
      Below we will explore further and provide more explanations for this behaviour
    </dt-fn>
  </p>
  <figure class='l-body'>
  <img src="pytorch_ca/Presentation_images/mask_80_.png" style='height: 45%; width: 45%; object-fit: contain' id="80%mask">
  <img src="pytorch_ca/Presentation_videos/mask-80_-correct.gif" style='height: 45%; width: 45%; object-fit: contain' id="80%video">
    <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
      Video 3: The rule switches at the 40th step with 80% of new cells, here the transition is not even noticeble
    </figcaption>
  </figure>
  <p>
    By the way, the density of new cells does not need to be uniform, it just needs to locally equal
    or higher than the minimum percentage
  </p>
  <figure class='l-page side'>
    <img src="pytorch_ca/Presentation_images/mask_by_percentage.svg" style='height: 100%; width: 100%; object-fit: contain' id="mask_swich">
    <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
      Figure: Evaluation loss as the percentage of cells substituted changes, to have an image close to the target
      the loss should be less than $10^{-2}$, so we can see that after 300 iterations most of the CAs decay,
      while only the ones with more than 95% of the cells substituted survives until the end
    </figcaption>
  </figure>
  <p>
    One of the problems is that the effectiveness of the mask decreases as you increase the number of steps,
    however it still significantly increase the lifespan of the CA.
  </p>
  <p>
    In particular from our tests we need a bare minimum of 70% of new cells to be able to increase the lifespan
    of the growing CA of a order of magnitude and at least 95% of new cells to be able to make the CA persist indefinitely.
  </p>
  <p>  
    In the graph on the left we plotted the loss as a function of the percentage of cells substituted with
    the Growing rule
  </p>
  
  <p>
    In order to better understand the graph, below we plotted some images and the corresponding losses 
  </p>

  <div style="height:10px"></div>

  <figure class='l-body'>
    <img src="pytorch_ca/Presentation_images/loss_5e-3.png" style='height: 32%; width: 32%; object-fit: contain' id="80%mask">
    <img src="pytorch_ca/Presentation_images/loss_1e-2.png" style='height: 32%; width: 32%; object-fit: contain' id="80%video">
    <img src="pytorch_ca/Presentation_images/loss_5e-2.png" style='height: 32%; width: 32%; object-fit: contain' id="80%mask">
    <div style="position:relative; height:30px; display:flex">
      <div style="width:33%; top:0px; text-align:center">$5\times 10^{-3}$</div>
      <div style="width:33%; top:0px; text-align:center">$1\times 10^{-2}$</div>
      <div style="width:33%; top:0px; text-align:center">$5\times 10^{-2}$</div>
    </div>
      <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
        Figure: Corresponging images as the loss changes, we can see that for losses $\approx 5\times 10^2$
        the image starts to deteriorate significantly
      </figcaption>
  </figure>












  <dt-byline></dt-byline>
  <h2><a class="marker" href="#section-3" id="section-3">3</a> Virus with evolving mask</h2>
  <p>
    One of the limitations of the fixed mask is that it can’t model what happens when a kind of cells
    overtakes the other. This is very important because having the new cells overtake the old ones would be both more biologically plausible and would help
    to reduce the minimum percentage of initial cells that need to change update rule.
    In an ideal case, we would only substitute a small percentage of cells, then these would be able to gradually overtake the entire organism,
    making it immortal.
    <dt-fn>
      The minimum percentage required depends from the speed of the aging process, if it's slow
      you can start with fewer cells since they will have plenty of time to overtake the old ones
    </dt-fn>
  </p>
  <figure class="l-body">
    <img src="pytorch_ca/images/evoluzione.svg" style='height: 100%; width: 100%; object-fit: contain' id="evo">
    <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
      The idea is that the new cells learn to overtake the old one and than make the organism immortal,
      so you need to inject fewer cells in the new organism
    </figcaption>
  </figure>
  <p>
    To be able to answer this we first have to ask ourselves how do we model the evolution of the mask? 
  </p>
  <h3><a class="marker" href="#section-3.1" id="section-3.1">3.1</a> The Model</h2>
  <p>
    For simplicity we are going to restrict ourself in the case where we are going to have 2 rules ($f_1$ and $f_2$). 
  </p>
  <p>
    Before, a cell state was represented by a state vector having the first 4 components representing
    the RGBA of the pixel and the remaining were hidden channels that helped the CA pass more
    information between its cells. If the $\alpha$ channel (transparency) is >0.1 it means
    that the cell is alive, otherwise it’s dead
  </p> 
  <p>
    If we are going to have two different types of cells we are going to need two alpha channels.
    Since a cell cannot be of both kinds at the same time we choose that if $\alpha_1$ is $>0.1$, then
    $\alpha_2$ must be 0, and the cell update follows $f_1$ and vice versa.
  </p>
  <p>
    When both alphas are below $0.1$, then the cell evolves with the sum of both updates.    
  </p>
  <div class="l-middle">
    <figure style='float:left; height: 50%; width: 50%;'>
      <img src="pytorch_ca/Presentation_images/evolving_mask.png" style='height: 100%; width: 100%; object-fit: contain' id="evolving_mask">
      <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
        Image 1: In this image the red cells evolve following $f_1$, the yellow
        follow $f_2$ and the orange ones follow both
      </figcaption>
    </figure>
    <figure style='float:right; height: 50%; width: 50%;'>
      <img src="pytorch_ca/images/Canali.svg" style='height: 100%; width: 100%; object-fit: contain'>
      <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 100%" >
        Image 2: On the vector on the left represents the old represetation of the CA state, and the one
        on the right is the new representation. This new representation of the cells has an additional
        $\alpha$ channel and to make the code simpler the alpha channels now are the last two components 
      </figcaption>
    </figure> 
  </div>  


  <h3><a class="marker" href="#section-3.2" id="section-3.2">3.2</a> Results</h2>
  <p>
    The test we have made so far are unsuccesful, this is because the cells that follow the Growing rule (red),
    if they are not sorrounded by the adversarial cells (yellow) will tend to explode.
  </p>
  <figure class="l-body">
    <div style="float:left; width:49%; height:49%;">
    <video loop="" autoplay="" playsinline="" muted="" width="100%" height="100%">
      <source src="pytorch_ca/Presentation_videos/alphas_no.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <figcaption>
      This is what happens when a old cell is not surrounded by the new cells
    </figcaption>
    </div>
    <div style="float:right; width:49%; height:49%;">
    <video loop="" autoplay="" playsinline="" muted="" width="100%" height="100%">
      <source src="pytorch_ca/Presentation_videos/alphas_yes.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <figcaption>
      This is what happens when a old cell is surrounded by the new cells
    </figcaption>
    </div>
  </figure>
  <h3><a class="marker" href="#section-3.3" id="section-3.3">3.3</a> Conclusion</h2>

  <p>
    *Work in progress, we are trying to solve this problem* 
  </p>
  
  
  






  
  
  <dt-byline></dt-byline>
  <h2><a class="marker" href="#section-4" id="section-4">4</a> Adding a perturbation</h2>
  <p>
    We wanted to know if we can add a small perturbation to the output of a growing cellular automata
    in order to make it a persistent one, this is very interesting from a biological perspective
    because we can answer the question: 
  </p>
  <figure class="l-middle side">
    <img src="pytorch_ca/Presentation_videos/perturbation_l_10.gif" style='height: 100%; width: 100%; object-fit: contain' id="perturbation">
    <figcaption style="align-self: center; margin-top: 20px; margin-bottom: 25px; width: 704px" >
      Video 3: Perturbation with $\lambda=10$ METTI QUELLA GIUSTA NUOVA
    </figcaption>
  </figure>
  <p>
    How much do we need to change the rule (or DNA) in order to have a newborn non-aging organism? 
  </p>
  <h3><a class="marker" href="#section-4.1" id="section-4.1">4.1</a> The Model</h2>

  <p>
    We model the perturbation as a function of the cell state, note that the perturbation can be any
    function of the cell state, however we chose to use another CA to model it. Finally we compute the
    next cell state as a sum of both the growing and the perturbation
    $$
      w_\textrm{new}=w_\textrm{growing}+ \Delta w
    $$
  </p>
  <p>
    To prevent that the perturbation will overwrite the growing part we added an additional term in the loss,
    this term penalizes the L2 norm of the perturbation $|\Delta w|^2$, this term keeps the perturbation
    weights as low as possible and avoids that the perturbation will overwrite the growing part of the rule
  </p>
  <h3><a class="marker" href="#section-4.2" id="section-4.2">4.2</a> Results</h2>

  <p>
    It turns out that a very little perturbation can make the growing CA a persistent or even
    a regenerating one. Below there is some data and on the side a video that shows the resulting CA output
    $$
    \frac{|\Delta w|^2}{|w_\textrm{growing}|^2}=0.17
    $$
    $$
    \frac{\langle w_{\textrm{new}}, w_\textrm{growing}\rangle}{|w_\textrm{growing}||w_{\textrm{new}}|}=0.914
    $$
  </p>
  <p>
    There is also an unexpected result!, If you take this model and you use it as a Switch it works, not only that, it also works as a Mask with
    a decent performance up to a percentage with 80%
    </p>
  <h3><a class="marker" href="#section-4.3" id="section-4.3">4.3</a> Conclusion</h2>
  <p>
    The rule that the growing learned is very close to a persistent/regenerating one, could this
    mean that we need a very little change in the DNA to make a real organism immortal? 
  </p>


</dt-article>

<dt-appendix>
  <h3>Glossary</h3>
  <ul>
    <li>Growing: CA trained to reach the target image in a finite number of steps, but then it can do whatever it wants</li>
    <li>Persist: CA trained to reach the target image in a finite number of steps and then keep its shape </li>
    <li>Regenerating: CA trained to reach the target image in a finite number of steps, keep its shape and be able to resist damage</li>
    <li>Switch</li>
    <li>Mask</li>
    <li>Virus</li>
    <li>Perturbation</li>
  </ul>
</dt-appendix>

<script type="text/bibliography">
  @article{mordvintsev2020growing,
    author = {Mordvintsev, Alexander and Randazzo, Ettore and Niklasson, Eyvind and Levin, Michael},
    title = {Growing Neural Cellular Automata},
    journal = {Distill},
    year = {2020},
    url = {https://distill.pub/2020/growing-ca},
  }

  @article{randazzo2021adversarial,
    author = {Randazzo, Ettore and Mordvintsev, Alexander and Niklasson, Eyvind and Levin, Michael},
    title = {Adversarial Reprogramming of Neural Cellular Automata},
    journal = {Distill},
    year = {2021},
    url = {https://distill.pub/selforg/2021/adversarial},
    doi = {10.23915/distill.00027.004}
  }
  @article{handberg2008stem,
    title={Stem cells and regeneration in planarians},
    author={Handberg-Thorsager, Mette and Fernandez, Enrique and Salo, Emili},
    journal={Front Biosci},
    volume={13},
    pages={6374--6394},
    year={2008},
    url ={https://www.fbscience.com/Landmark/articles/pdf/Landmark3160.pdf}
  }

  @article{TransmembraneVoltagePotential,
    author = {Pai, Vaibhav P. and Aw, Sherry and Shomrat, Tal and Lemire, Joan M. and Levin, Michael},
    title = "{Transmembrane voltage potential controls embryonic eye patterning in Xenopus laevis}",
    journal = {Development},
    volume = {139},
    number = {2},
    pages = {313-323},
    year = {2012},
    month = {01},
    issn = {0950-1991},
    doi = {10.1242/dev.073759},
    url = {https://doi.org/10.1242/dev.073759},
    eprint = {https://journals.biologists.com/dev/article-pdf/139/2/313/1160014/313.pdf}
}

</script>